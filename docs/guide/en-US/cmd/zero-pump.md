## zero-pump

Launch a zero pump server

### Synopsis

Pump is a pluggable analytics purger to move Analytics generated by your zero nodes to any back-end.

Find more zero-pump information at:
    https://github.com/superproj/zero/blob/master/docs/guide/en-US/cmd/zero-pump.md

```
zero-pump [flags]
```

### Options

```
  -c, --config FILE                                Read configuration from specified FILE, support JSON, TOML, YAML, HCL, or Java properties formats.
      --feature-gates mapStringBool                A set of key=value pairs that describe feature gates for alpha/experimental features. Options are:
                                                   AllAlpha=true|false (ALPHA - default=false)
                                                   AllBeta=true|false (BETA - default=false)
                                                   ContextualLogging=true|false (ALPHA - default=false)
                                                   LoggingAlphaOptions=true|false (ALPHA - default=false)
                                                   LoggingBetaOptions=true|false (BETA - default=true)
                                                   MachinePool=true|false (ALPHA - default=false)
      --health.check-address string                Specifies liveness health check bind address. (default "0.0.0.0:9090")
      --health.check-path string                   Specifies liveness health check request path. (default "healthz")
      --health.enable-http-profiler                Expose runtime profiling data via HTTP.
  -h, --help                                       help for zero-pump
      --kafka.algorithm string                     Algorithm used to create sasl.Mechanism.
      --kafka.brokers strings                      The list of brokers used to discover the partitions available on the kafka cluster.
      --kafka.client-id string                      Unique identifier for client connections established by this Dialer. 
      --kafka.compressed                           compressed is used to specify whether compress Kafka messages.
      --kafka.mechanism string                     Configures the Dialer to use SASL authentication.
      --kafka.password string                      Password of the kafka cluster.
      --kafka.reader.commit-interval duration      CommitInterval indicates the interval at which offsets are committed to the broker.
      --kafka.reader.group-id string               GroupID holds the optional consumer group id. If GroupID is specified, then Partition should NOT be specified e.g. 0.
      --kafka.reader.heartbeat-interval duration   HeartbeatInterval sets the optional frequency at which the reader sends the consumer group heartbeat update. (default 3s)
      --kafka.reader.max-attempts int              Limit of how many attempts will be made before delivering the error.  (default 3)
      --kafka.reader.max-bytes int                 MaxBytes indicates to the broker the maximum batch size that the consumer will accept. (default 1048576)
      --kafka.reader.max-wait duration             Maximum amount of time to wait for new data to come when fetching batches of messages from kafka. (default 10s)
      --kafka.reader.min-bytes int                 MinBytes indicates to the broker the minimum batch size that the consumer will accept. (default 1)
      --kafka.reader.partition int                 Partition to read messages from.
      --kafka.reader.queue-capacity int            The capacity of the internal message queue, defaults to 100 if none is set. (default 100)
      --kafka.reader.read-batch-timeout duration   ReadBatchTimeout amount of time to wait to fetch message from kafka messages batch. (default 10s)
      --kafka.reader.rebalance-timeout duration    RebalanceTimeout optionally sets the length of time the coordinator will wait for members to join as part of a rebalance. (default 30s)
      --kafka.reader.start-offset int              StartOffset determines from whence the consumer group should begin consuming when it finds a partition without a committed offset. (default -2)
      --kafka.required-acks int                    Number of acknowledges from partition replicas required before receiving a response to a produce request. (default 1)
      --kafka.timeout duration                     Timeout is the maximum amount of time a dial will wait for a connect to complete. (default 3s)
      --kafka.tls.ca-cert string                   Path to ca cert for connecting to the server.
      --kafka.tls.cert string                      Path to cert file for connecting to the server.
      --kafka.tls.insecure-skip-verify             Controls whether a client verifies the server's certificate chain and host name.
      --kafka.tls.key string                       Path to key file for connecting to the server.
      --kafka.tls.use-tls                          Use tls transport to connect the server.
      --kafka.topic string                         The topic that the writer/reader will produce/consume messages to.
      --kafka.username string                      Username of the kafka cluster.
      --kafka.writer.async                         Limit on how many attempts will be made to deliver a message. (default true)
      --kafka.writer.batch-bytes int               Limit the maximum size of a request in bytes before being sent to a partition. (default 1048576)
      --kafka.writer.batch-size int                Limit on how many messages will be buffered before being sent to a partition. (default 100)
      --kafka.writer.batch-timeout duration        Time limit on how often incomplete message batches will be flushed to kafka. (default 1s)
      --kafka.writer.max-attempts int              Limit on how many attempts will be made to deliver a message. (default 10)
      --mongo.collection-name string               The mongo collection name.
      --mongo.timeout duration                     Timeout is the maximum amount of time a dial will wait for a connect to complete. (default 30s)
      --mongo.tls.ca-cert string                   Path to ca cert for connecting to the server.
      --mongo.tls.cert string                      Path to cert file for connecting to the server.
      --mongo.tls.insecure-skip-verify             Controls whether a client verifies the server's certificate chain and host name.
      --mongo.tls.key string                       Path to key file for connecting to the server.
      --mongo.tls.use-tls                          Use tls transport to connect the server.
      --mongo.url string                           The mongo server address.
      --redis.addr string                          Address of your Redis server(ip:port). (default "127.0.0.1:6379")
      --redis.database int                         Database to be selected after connecting to the server.
      --redis.dial-timeout duration                Dial timeout for establishing new connections. (default 5s)
      --redis.enable-trace                         Redis hook tracing (using open telemetry).
      --redis.max-retries int                      Maximum number of retries before giving up. (default 3)
      --redis.min-idle-conn int                    Minimum number of idle connections which is useful when establishing new connection is slow.
      --redis.password string                      Optional auth password for redis db.
      --redis.pool-size int                        Maximum number of socket connections. (default 10)
      --redis.pool-timeout duration                Amount of time client waits for connection if all connections are busy before returning an error.
      --redis.read-timeout duration                Timeout for socket reads. (default 3s)
      --redis.username string                      Username for access to redis service.
      --redis.write-timeout duration               Timeout for socket writes.
      --version version[=true]                     Print version information and quit
```

###### Auto generated by spf13/cobra on 21-Jul-2023
